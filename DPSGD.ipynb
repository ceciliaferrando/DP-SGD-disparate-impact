{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import softmax, expit\n",
    "from scipy.stats import norm\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing MNIST from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('mnist_train.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing: create a basic unbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = 2000\n",
    "N_val = 400\n",
    "N_test = 1000\n",
    "n_unbal = 20 \n",
    "\n",
    "train_X, train_Y = data[:N_train,1:], data[:N_train,0].astype(int)\n",
    "val_X, val_Y = data[N_train:N_train+N_val,1:], data[N_train:N_train+N_val,0].astype(int)\n",
    "test_X, test_Y = data[N_train+N_val:N_train+N_val+N_test,1:], data[N_train+N_val:N_train+N_val+N_test,0].astype(int)\n",
    "\n",
    "print(val_Y)\n",
    "\n",
    "indices_8 = np.where(train_Y==8)\n",
    "train_X_only_eight = train_X[train_Y==8]\n",
    "\n",
    "idx_sampled = np.random.choice(train_X_only_eight.shape[0], n_unbal, replace=False)\n",
    "\n",
    "train_X_only_eight = train_X[train_Y==8,:]\n",
    "plt.imshow(train_X_only_eight[1,:].reshape(28,28))\n",
    "train_X_unbal = np.vstack((\n",
    "    train_X_only_eight[idx_sampled],\n",
    "    train_X[train_Y != 8,:]\n",
    "))\n",
    "\n",
    "train_Y_only_eight = train_Y[train_Y==8]\n",
    "train_Y_unbal = np.concatenate((\n",
    "    train_Y_only_eight[idx_sampled],\n",
    "    train_Y[train_Y != 8]\n",
    "))\n",
    "\n",
    "\n",
    "print(np.sum(train_Y_unbal==8))\n",
    "print(train_X_unbal[np.where(train_Y_unbal==3)])\n",
    "print(train_Y_unbal.shape)\n",
    "\n",
    "def normalize(M):\n",
    "    M = (M-min(M))/(max(M)-min(M))\n",
    "    return(M)\n",
    "\n",
    "def oneHotEncode(Y):\n",
    "    onehot_encoded = []\n",
    "    for value in Y:\n",
    "        zero_vec = [0]*10\n",
    "        zero_vec[value] = 1\n",
    "        onehot_encoded.append(zero_vec)\n",
    "    return np.array(onehot_encoded)\n",
    "\n",
    "train_X_unbal = np.apply_along_axis(normalize, 1, train_X_unbal)\n",
    "val_X = np.apply_along_axis(normalize, 1, val_X)\n",
    "test_X = np.apply_along_axis(normalize, 1, test_X)\n",
    "\n",
    "where_test_8 = np.where(test_Y==8)\n",
    "where_test_o = np.where(test_Y!=8)\n",
    "\n",
    "train_Y_unbal = oneHotEncode(train_Y_unbal)\n",
    "val_Y = oneHotEncode(val_Y)\n",
    "test_Y = oneHotEncode(test_Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(s):\n",
    "    return expit(s)\n",
    "\n",
    "def sigmoid_derivative(s):\n",
    "    return s * (1 - s)\n",
    "\n",
    "def one_hot_encoding(real):\n",
    "    if type(real)==int:\n",
    "        encode = np.zeros((10,))\n",
    "        encode[int(real)] = 1\n",
    "        return(np.array([encode]))\n",
    "    else:\n",
    "        encode = np.zeros((len(real),10))\n",
    "        for i in range(len(real)):\n",
    "            encode[i,real[i]] = 1\n",
    "        return(np.array(encode))\n",
    "\n",
    "def cross_entropy_derivative(pred, real):\n",
    "\n",
    "    n_samples = real.shape[0]\n",
    "    res = pred - real\n",
    "    return res/n_samples\n",
    "\n",
    "def error(pred, real):\n",
    "    n_samples = real.shape[0]\n",
    "    logp = - np.log(pred[np.arange(n_samples), real.argmax(axis=1)])\n",
    "    loss = np.sum(logp)/n_samples\n",
    "    return loss\n",
    "\n",
    "def clip_L2_norm(vec, C):\n",
    "    vec = vec/max(1, np.linalg.norm(vec)/C)\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mnistNN:\n",
    "    def __init__(self, N, D, K, L1, L2, lr):\n",
    "        \n",
    "        self.neurons1 = L1\n",
    "        self.neurons2 = L2\n",
    "        self.lr = lr\n",
    "\n",
    "        self.w1 = np.random.randn(D, self.neurons1)\n",
    "        self.b1 = np.zeros((1, self.neurons1))\n",
    "        self.w2 = np.random.randn(self.neurons1, self.neurons2)\n",
    "        self.b2 = np.zeros((1, self.neurons2))\n",
    "        self.w3 = np.random.randn(self.neurons2, K)\n",
    "        self.b3 = np.zeros((1, K))\n",
    "        \n",
    "        self.gw1 = np.zeros((D, self.neurons1))\n",
    "        self.gb1 = np.zeros((1, self.neurons1))\n",
    "        self.gw2 = np.zeros((self.neurons1, self.neurons2))\n",
    "        self.gb2 = np.zeros((1, self.neurons2))\n",
    "        self.gw3 = np.zeros((self.neurons2, K))\n",
    "        self.gb3 = np.zeros((1, K))\n",
    "\n",
    "    def feedforward(self, x):\n",
    "        \n",
    "        # layer 1\n",
    "        z1 = np.dot(x, self.w1) + self.b1\n",
    "        self.a1 = sigmoid(z1)\n",
    "        # layer 2\n",
    "        z2 = np.dot(self.a1, self.w2) + self.b2\n",
    "        self.a2 = sigmoid(z2)\n",
    "        # output layer\n",
    "        z3 = np.dot(self.a2, self.w3) + self.b3\n",
    "        self.a3 = softmax(z3)\n",
    "        \n",
    "    def computegradients(self, x, y):\n",
    "        \n",
    "        #backwards from output layer to input\n",
    "        a3_delta = cross_entropy_derivative(self.a3, y) # w3\n",
    "        z2_delta = np.dot(a3_delta, self.w3.T)\n",
    "        a2_delta = z2_delta * sigmoid_derivative(self.a2) # w2\n",
    "        z1_delta = np.dot(a2_delta, self.w2.T)\n",
    "        a1_delta = z1_delta * sigmoid_derivative(self.a1) # w1\n",
    "        \n",
    "        gw3 = np.dot(self.a2.T, a3_delta)\n",
    "        gb3 = np.sum(a3_delta, axis=0, keepdims=True)\n",
    "        gw2 = np.dot(self.a1.T, a2_delta)\n",
    "        gb2 = np.sum(a2_delta, axis=0)\n",
    "        gw1 = np.dot(x.T.reshape(-1,1), a1_delta)\n",
    "        gb1 = np.sum(a1_delta, axis=0) \n",
    "        \n",
    "        return {'gw3': gw3, 'gb3': gb3, 'gw2': gw2, 'gb2': gb2, 'gw1': gw1, 'gb1': gb1}\n",
    "            \n",
    "            \n",
    "    def descent(self, x, y, gradients):\n",
    "        \n",
    "        # update gradient\n",
    "        self.w3 -= self.lr * gradients['gw3']\n",
    "        self.b3 -= self.lr * gradients['gb3']\n",
    "        self.w2 -= self.lr * gradients['gw2']\n",
    "        self.b2 -= self.lr * gradients['gb2']\n",
    "        self.w1 -= self.lr * gradients['gw1']\n",
    "        self.b1 -= self.lr * gradients['gb1']\n",
    "\n",
    "    def predict(self, x):\n",
    "        self.feedforward(x)\n",
    "        return self.a3.argmax()\n",
    "    \n",
    "    def get_loss(self, x, y):\n",
    "        loss = 0\n",
    "        for xx,yy in zip(x, y):\n",
    "            self.feedforward(xx)\n",
    "            s = self.a3\n",
    "            current_loss = error(s, np.array([yy]))\n",
    "            loss += current_loss\n",
    "        return loss/len(x)\n",
    "    \n",
    "    def get_acc(self, x, y):\n",
    "        acc = 0\n",
    "        for xx,yy in zip(x, y):\n",
    "            s = self.predict(xx)\n",
    "            if s == np.argmax(yy):\n",
    "                acc +=1\n",
    "        return acc/len(x)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NON-DP MODEL (UNBALANCED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "N, D = train_X_unbal.shape\n",
    "L = 500\n",
    "K = 10\n",
    "L1 = 128\n",
    "L2 = 128\n",
    "lr = 0.5\n",
    "batch_size = 1\n",
    "epochs = 200\n",
    "np.random.seed(3)\n",
    "\n",
    "# create model\n",
    "model = mnistNN(N, D, K, L1, L2, lr)\n",
    "\n",
    "labels_per_epoch = []\n",
    "loss_vec = []\n",
    "acc_train_vec = []\n",
    "acc_test_vec = []\n",
    "acc_o_train_vec = []\n",
    "acc_8_train_vec = []\n",
    "acc_o_test_vec = []\n",
    "acc_8_test_vec = []\n",
    "\n",
    "# train\n",
    "for e in range(epochs):\n",
    "    \n",
    "    idx = list(range(L))\n",
    "    np.random.shuffle(idx)\n",
    "    \n",
    "    labels = []\n",
    "    \n",
    "    #store gradients across data points\n",
    "    \n",
    "    # loop through datapoints\n",
    "    for i in idx:\n",
    "        x_i, y_i = train_X_unbal[i,:], np.array([train_Y_unbal[i]])\n",
    "        labels.append(np.where(train_Y_unbal[i]==1)[0].tolist()[0])\n",
    "        model.feedforward(x_i)\n",
    "        gradients = model.computegradients(x_i, y_i)\n",
    "\n",
    "        model.gw1 += gradients['gw1']\n",
    "        model.gb1 += gradients['gb1']\n",
    "        model.gw2 += gradients['gw2']\n",
    "        model.gb2 += gradients['gb2']\n",
    "        model.gw3 += gradients['gw3']\n",
    "        model.gb3 += gradients['gb3']\n",
    "        \n",
    "    #take average and update parameters\n",
    "    \n",
    "    gw1_avg = model.gw1/L\n",
    "    gb1_avg = model.gb1/L\n",
    "    gw2_avg = model.gw2/L\n",
    "    gb2_avg = model.gb2/L\n",
    "    gw3_avg = model.gw3/L\n",
    "    gb3_avg = model.gb3/L\n",
    "    \n",
    "    \n",
    "    model.descent(x_i, y_i, {'gw3': gw3_avg, 'gb3': gb3_avg, 'gw2': gw2_avg, \n",
    "                                    'gb2': gb2_avg, 'gw1': gw1_avg, 'gb1': gb1_avg})\n",
    "    \n",
    "    loss = model.get_loss(train_X_unbal, train_Y_unbal)\n",
    "    loss_vec.append(loss)\n",
    "    \n",
    "    #reset gradients in memory\n",
    "    \n",
    "    model.gw1 = np.zeros((D, L1))\n",
    "    model.gb1 = np.zeros((1, L1))\n",
    "    model.gw2 = np.zeros((L1, L2))\n",
    "    model.gb2 = np.zeros((1, L2))\n",
    "    model.gw3 = np.zeros((L2, K))\n",
    "    model.gb3 = np.zeros((1, K))\n",
    "    \n",
    "    #save results\n",
    "    \n",
    "    x_train_8 = train_X_unbal[where_test_8]\n",
    "    y_train_8 = train_Y_unbal[where_test_8]\n",
    "    x_train_o = train_X_unbal[where_test_o]\n",
    "    y_train_o = train_Y_unbal[where_test_o]\n",
    "    x_test_8 = test_X[where_test_8]\n",
    "    y_test_8 = test_Y[where_test_8]\n",
    "    x_test_o = test_X[where_test_o]\n",
    "    y_test_o = test_Y[where_test_o]\n",
    "    \n",
    "    \n",
    "    acc_train_vec.append(model.get_acc(train_X_unbal, train_Y_unbal))\n",
    "    acc_test_vec.append(model.get_acc(test_X, test_Y))\n",
    "    acc_o_train_vec.append(model.get_acc(x_train_o, y_train_o))\n",
    "    acc_8_train_vec.append(model.get_acc(x_train_8, y_train_8))\n",
    "    acc_o_test_vec.append(model.get_acc(x_test_o, y_test_o))\n",
    "    acc_8_test_vec.append(model.get_acc(x_test_8, y_test_8))\n",
    "         \n",
    "         \n",
    "    if e%20 == 1:\n",
    "        x_test_8 = test_X[where_test_8]\n",
    "        y_test_8 = test_Y[where_test_8]\n",
    "        x_test_o = test_X[where_test_o]\n",
    "        y_test_o = test_Y[where_test_o]\n",
    "        print('epoch ', e)\n",
    "        print('avg loss ', np.mean(loss_vec))\n",
    "        print('train accuracy ', model.get_acc(train_X_unbal, train_Y_unbal))\n",
    "        print('test accuracy ', model.get_acc(test_X, test_Y))\n",
    "        print('len of test set other ', len(y_test_o))\n",
    "        print('test accuracy other', model.get_acc(x_test_o, y_test_o))\n",
    "        print('len of test set unbal ', len(y_test_8))\n",
    "        print('test accuracy unbal', model.get_acc(x_test_8, y_test_8))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        \n",
    "    labels_per_epoch.append(labels)\n",
    "    \n",
    "    lr = lr * 0.99\n",
    "    \n",
    "    \n",
    "suffix = \"_batch\" + str(L) + \"_C\" + str(C) + \"_noisescale\" + str(noise_scale) + \".npy\"\n",
    "np.save(\"loss_vec\"+suffix, loss_vec)\n",
    "np.save(\"acc_train_vec\" + suffix, acc_train_vec)\n",
    "np.save(\"acc_test_vec\" + suffix, acc_test_vec)\n",
    "np.save(\"acc_o_train_vec\" + suffix, acc_o_train_vec)\n",
    "np.save(\"acc_8_train_vec\" + suffix, acc_8_train_vec)\n",
    "np.save(\"acc_o_test_vec\" + suffix, acc_o_test_vec)\n",
    "np.save(\"acc_8_test_vec\" + suffix, acc_8_test_vec)\n",
    "        \n",
    "print(model.get_acc(x_test_o, y_test_o))\n",
    "print(model.get_acc(x_test_8, y_test_8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "N, D = train_X_unbal.shape\n",
    "L = 500\n",
    "K = 10\n",
    "L1 = 128\n",
    "L2 = 128\n",
    "lr = 0.5\n",
    "dp = True\n",
    "C = 1\n",
    "noise_scale = 0.5\n",
    "epochs = 200\n",
    "np.random.seed(3)\n",
    "\n",
    "# create model\n",
    "modelDP = mnistNN(N, D, K, L1, L2, lr)\n",
    "\n",
    "#storage\n",
    "\n",
    "labels_per_epoch = []\n",
    "\n",
    "loss_vec_DP = []\n",
    "acc_train_vec_DP = []\n",
    "acc_test_vec_DP = []\n",
    "acc_o_train_vec_DP = []\n",
    "acc_8_train_vec_DP = []\n",
    "acc_o_test_vec_DP = []\n",
    "acc_8_test_vec_DP = []\n",
    "\n",
    "\n",
    "# train\n",
    "for e in range(epochs):\n",
    "    \n",
    "    idx = list(range(L))\n",
    "    np.random.shuffle(idx)\n",
    "    \n",
    "    labels = []\n",
    "    \n",
    "    # loop through datapoints\n",
    "    for i in idx:\n",
    "        x_i, y_i = train_X_unbal[i,:], np.array([train_Y_unbal[i]])\n",
    "        labels.append(np.where(train_Y_unbal[i]==1)[0].tolist()[0])\n",
    "        modelDP.feedforward(x_i)\n",
    "        gradients = modelDP.computegradients(x_i, y_i)\n",
    "\n",
    "        modelDP.gw1 += clip_L2_norm(gradients['gw1'], C)\n",
    "        modelDP.gb1 += clip_L2_norm(gradients['gb1'], C)\n",
    "        modelDP.gw2 += clip_L2_norm(gradients['gw2'], C)\n",
    "        modelDP.gb2 += clip_L2_norm(gradients['gb2'], C)\n",
    "        modelDP.gw3 += clip_L2_norm(gradients['gw3'], C)\n",
    "        modelDP.gb3 += clip_L2_norm(gradients['gb3'], C)\n",
    "\n",
    "    \n",
    "    modelDP.gw1 = (modelDP.gw1 + np.random.normal(loc=0, scale = noise_scale**2 * C**2, size = modelDP.gw1.shape))/L\n",
    "    modelDP.gb1 = (modelDP.gb1 + np.random.normal(loc=0, scale = noise_scale**2 * C**2, size = modelDP.gb1.shape))/L\n",
    "    modelDP.gw2 = (modelDP.gw2 + np.random.normal(loc=0, scale = noise_scale**2 * C**2, size = modelDP.gw2.shape))/L\n",
    "    modelDP.gb2 = (modelDP.gb2 + np.random.normal(loc=0, scale = noise_scale**2 * C**2, size = modelDP.gb2.shape))/L\n",
    "    modelDP.gw3 = (modelDP.gw3 + np.random.normal(loc=0, scale = noise_scale**2 * C**2, size = modelDP.gw3.shape))/L\n",
    "    modelDP.gb3 = (modelDP.gb3 + np.random.normal(loc=0, scale = noise_scale**2 * C**2, size = modelDP.gb3.shape))/L\n",
    "        \n",
    "\n",
    "    \n",
    "    modelDP.descent(x_i, y_i, {'gw3': modelDP.gw3, 'gb3': modelDP.gb3, 'gw2': modelDP.gw2, \n",
    "                                    'gb2': modelDP.gb2, 'gw1': modelDP.gw1, 'gb1': modelDP.gb1})\n",
    "    \n",
    "    loss = modelDP.get_loss(train_X_unbal, train_Y_unbal)\n",
    "    loss_vec_DP.append(loss)\n",
    "    \n",
    "    #reset gradients in memory\n",
    "    \n",
    "    modelDP.gw1 = np.zeros((D, L1))\n",
    "    modelDP.gb1 = np.zeros((1, L1))\n",
    "    modelDP.gw2 = np.zeros((L1, L2))\n",
    "    modelDP.gb2 = np.zeros((1, L2))\n",
    "    modelDP.gw3 = np.zeros((L2, K))\n",
    "    modelDP.gb3 = np.zeros((1, K))\n",
    "    \n",
    "    \n",
    "    #save results\n",
    "    \n",
    "    x_train_8 = train_X_unbal[where_test_8]\n",
    "    y_train_8 = train_Y_unbal[where_test_8]\n",
    "    x_train_o = train_X_unbal[where_test_o]\n",
    "    y_train_o = train_Y_unbal[where_test_o]\n",
    "    x_test_8 = test_X[where_test_8]\n",
    "    y_test_8 = test_Y[where_test_8]\n",
    "    x_test_o = test_X[where_test_o]\n",
    "    y_test_o = test_Y[where_test_o]\n",
    "    \n",
    "    \n",
    "    acc_train_vec_DP.append(modelDP.get_acc(train_X_unbal, train_Y_unbal))\n",
    "    acc_test_vec_DP.append(modelDP.get_acc(test_X, test_Y))\n",
    "    acc_o_train_vec_DP.append(modelDP.get_acc(x_train_o, y_train_o))\n",
    "    acc_8_train_vec_DP.append(modelDP.get_acc(x_train_8, y_train_8))\n",
    "    acc_o_test_vec_DP.append(modelDP.get_acc(x_test_o, y_test_o))\n",
    "    acc_8_test_vec_DP.append(modelDP.get_acc(x_test_8, y_test_8))\n",
    "         \n",
    "    if e%20 == 1:\n",
    "        \n",
    "        print('epoch ', e)\n",
    "        print('avg loss ', np.mean(loss_vec_DP))\n",
    "        print('train accuracy ', modelDP.get_acc(train_X_unbal, train_Y_unbal))\n",
    "        print('test accuracy ', modelDP.get_acc(test_X, test_Y))\n",
    "        print('len of test set other ', len(y_test_o))\n",
    "        print('test accuracy other', modelDP.get_acc(x_test_o, y_test_o))\n",
    "        print('len of test set unbal ', len(y_test_8))\n",
    "        print('test accuracy unbal', modelDP.get_acc(x_test_8, y_test_8))\n",
    "        print('\\n')\n",
    "        \n",
    "        \n",
    "    labels_per_epoch.append(labels)\n",
    "\n",
    "suffix = \"_batch\" + str(L) + \"_C\" + str(C) + \"_noisescale\" + str(noise_scale) + \".npy\"\n",
    "np.save(\"loss_vec_DP\" + suffix, loss_vec_DP)\n",
    "np.save(\"acc_train_vec_DP\" + suffix, acc_train_vec_DP)\n",
    "np.save(\"acc_test_vec_DP\" + suffix, acc_test_vec_DP)\n",
    "np.save(\"acc_o_train_vec_DP\" + suffix, acc_o_train_vec_DP)\n",
    "np.save(\"acc_8_train_vec_DP\" + suffix, acc_8_train_vec_DP)\n",
    "np.save(\"acc_o_test_vec_DP\" + suffix, acc_o_test_vec_DP)\n",
    "np.save(\"acc_8_test_vec_DP\" + suffix, acc_8_test_vec_DP)\n",
    "    \n",
    "print(modelDP.get_acc(x_test_o, y_test_o))\n",
    "print(modelDP.get_acc(x_test_8, y_test_8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
